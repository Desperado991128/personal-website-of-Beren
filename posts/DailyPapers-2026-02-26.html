<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily AI Research Papers - 2026-02-26</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['\\(','\\)']], displayMath: [['\\[','\\]']]}
        });
    </script>
    <style>
        body {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            font-size: 18px;
        }
        header {
            margin-bottom: 2rem;
            border-bottom: 1px solid #eaecef;
        }
        .site-title {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 2em;
            margin-bottom: 0.5em;
        }
        nav ul {
            display: flex;
            list-style: none;
            padding: 0;
            margin: 1rem 0;
        }
        nav ul li {
            margin-right: 1.5rem;
        }
        nav ul li a {
            text-decoration: none;
            color: #0366d6;
            font-weight: 600;
        }
        nav ul li a:hover {
            text-decoration: underline;
        }
        .container {
            width: 100%;
            max-width: 800px;
        }
        h1 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 2.4em;
            margin-bottom: 0.5em;
            line-height: 1.2;
        }
        h2 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 1.8em;
            margin-top: 1.5em;
            margin-bottom: 0.75em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        h3 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 1.5em;
            margin-top: 1.2em;
            margin-bottom: 0.6em;
        }
        h4 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 1.2em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }
        p {
            margin: 1em 0;
        }
        code {
            font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
            background: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-size: 0.9em;
        }
        pre {
            background: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow: auto;
            font-size: 0.9em;
        }
        blockquote {
            margin: 1em 0;
            padding: 0 1em;
            color: #6a737d;
            border-left: 0.25em solid #dfe2e5;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1.5em auto;
        }
        .meta {
            color: #6a737d;
            font-size: 0.9em;
            margin-bottom: 2em;
        }
        .post-meta {
            color: #6a737d;
            font-size: 0.9em;
            margin-bottom: 2em;
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
        }
        .figure-caption {
            text-align: center;
            color: #666;
            font-size: 0.9em;
            margin-top: -1em;
            margin-bottom: 2em;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 1.5em 0;
        }
        th, td {
            border: 1px solid #dfe2e5;
            padding: 8px 12px;
            text-align: left;
        }
        th {
            background-color: #f6f8fa;
        }
        tr:nth-child(even) {
            background-color: #f6f8fa;
        }
        #table-of-contents {
            background-color: #f8f9fa;
            padding: 1.5rem;
            border-radius: 5px;
            margin: 2rem 0;
        }
        #table-of-contents h3 {
            margin-top: 0;
            margin-bottom: 1rem;
        }
        #table-of-contents ol, #table-of-contents ul {
            margin-bottom: 0;
        }
        #table-of-contents a {
            text-decoration: none;
            color: #0366d6;
        }
        #table-of-contents a:hover {
            text-decoration: underline;
        }
        .post-content {
            margin-top: 2rem;
        }
        .paper-entry {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid #eaecef;
        }
        .paper-entry:last-child {
            border-bottom: none;
        }
        .paper-title {
            font-size: 1.3em;
            margin-bottom: 0.5em;
        }
        .paper-title a {
            color: #0366d6;
            text-decoration: none;
        }
        .paper-title a:hover {
            text-decoration: underline;
        }
        .paper-meta {
            color: #6a737d;
            font-size: 0.9em;
            margin-bottom: 1em;
        }
        .paper-topics {
            display: inline-flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 0.5rem;
        }
        .topic-tag {
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 0.2em 0.6em;
            border-radius: 3px;
            font-size: 0.85em;
        }
        footer {
            margin-top: 3rem;
            padding-top: 1rem;
            border-top: 1px solid #eaecef;
            font-size: 0.9em;
            color: #6a737d;
        }
        @media (max-width: 768px) {
            body {
                padding: 15px;
            }
            h1 {
                font-size: 2em;
            }
            h2 {
                font-size: 1.6em;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1 class="site-title">Beren's Blog</h1>
            <nav>
                <ul>
                  <li><a href="../index.html">Home</a></li>
                  <li><a href="../blog.html">Blog</a></li>
                  <li><a href="../gallery.html">Gallery</a></li>
                  <li><a href="../about.html">About</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="container">
        <article class="blog-post">
            <h2 class="post-title">Daily AI Research Papers</h2>
            <div class="post-meta">
                <span class="date">February 26, 2026</span>
                <span class="author">Beren Meng</span>
                <span class="label">AI Research Daily</span>
            </div>

            <div id="table-of-contents">
              <h3>Table of Contents</h3>
              <ol>
                <li><a href="#daily-concept">Daily Concept</a></li>
                <li><a href="#papers">Paper Summaries</a></li>
                <li><a href="#references">References</a></li>
              </ol>
            </div>

            <div class="post-content">
                <p>Here are selected AI research papers and a concept explainer for February 26, 2026.</p>

                <h2 id="daily-concept">Daily Concept: Recurrent vs parallel computation</h2>
                <p>### 1. What is it?<br>
Recurrent computation refers to a sequential processing paradigm where an operation at time step $t$ depends on the completed output of time step $t-1$. In contrast, parallel computation executes multiple operations simultaneously, allowing independent calculations to occur at the same time to maximize hardware efficiency.</p>

<p>### 2. How does it work?<br>
In recurrent architectures, the system maintains a hidden state $h_t$ that is updated iteratively using a function $f$ and the previous state $h_{t-1}$. This creates a dependency chain represented by \(h_t = f(h_{t-1}, x_t)\), which forces the processor to wait for step $t-1$ to finish before starting step $t$. Parallel computation avoids this strict sequential dependency, often through mechanisms like self-attention or convolution. This allows the model to process an entire sequence or batch simultaneously using matrix operations like \(\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V\).</p>

<p>### 3. Why does it matter?<br>
The distinction dictates the efficiency and feasibility of training modern Large Language Models. In Mixture of Experts models, parallel computation enables the efficient routing and processing of tokens across different experts without creating training bottlenecks. For unlearning and KANs (Kolmogorov-Arnold Networks), parallel architectures allow for targeted parameter updates and faster inference, whereas recurrent processing would introduce latency that complicates real-time applications.</p>

<p>### 4. Key insight. Recurrent computation offers lower memory usage for long sequences but suffers from training latency due to sequential bottlenecks. Parallel computation maximizes hardware utilization and training speed but typically requires significantly more memory to store intermediate states.</p>

                <h2 id="papers">Paper Summaries</h2>

                <div class="paper-entry" id="paper-1">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.22055v1" target="_blank">Physics-Informed Machine Learning for Vessel Shaft Power and Fuel Consumption Prediction: Interpretable KAN-based Approach</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>Authors:</strong> Hamza Haruna Mohammed, Dusica Marijan, Arnbj√∏rn Maressa<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.22055v1" target="_blank">2602.22055v1</a>
                    </div>
                    <div class="paper-topics">
                        <span class="topic-tag">kan</span>
                    </div>

                    <h4>Summary</h4>
                    <p>### 1. Research Question. How can we accurately predict vessel shaft power and fuel consumption while maintaining physical plausibility and interpretability? The paper addresses the trade-off between the high accuracy of data-driven models and the physical consistency provided by traditional physics-based approaches.</p>

<p>### 2. Positioning. Existing literature is divided between interpretable physics-based models that struggle with real-world variability and black-box neural networks that achieve accuracy but lack physical transparency. This work positions itself at the intersection of physics-informed machine learning and maritime engineering. It fills a critical gap by offering a solution that achieves high predictive performance without sacrificing the physical consistency required for operational decision support.</p>

<p>### 3. Key Contribution. The primary contribution is the Physics-Informed Kolmogorov-Arnold Network (PI-KAN), a hybrid architecture that integrates interpretable univariate feature transformations with a physics-informed loss function. The model demonstrates state-of-the-art accuracy on operational data from five cargo vessels, outperforming traditional polynomial methods and standard neural network baselines. Crucially, it provides interpretable insights, successfully rediscovering established physical relationships such as the cubic speed-power law.</p>

<p>### 4. Methodology. The authors propose a leakage-free chained prediction pipeline where shaft rotational speed, power, and fuel consumption are modeled sequentially using KANs. Unlike standard neural networks that use fixed activation functions on nodes, KANs employ learnable univariate functions on edges, allowing for more transparent feature transformations. The training process incorporates a physics-informed loss function to ensure the model outputs adhere to known maritime physical constraints.</p>

<p>### 5. Limitations. The study is limited by its focus on only five cargo vessels, which may restrict the generalizability of the findings to other ship types or distinct operational environments. While the KAN architecture is interpretable, it can be computationally more intensive to train and optimize compared to simpler regression models or standard Multi-Layer Perceptrons. Furthermore, the effectiveness of the physics-informed loss depends heavily on the correctness of the underlying physical equations used as constraints.</p>

<p>### 6. Critical Evaluation. This paper offers a significant advancement in maritime AI by demonstrating that high accuracy and physical interpretability are not mutually exclusive goals. The ability of the model to autonomously learn the cubic relationship between speed and power serves as a strong validation of the KAN architecture for scientific domains. However, the practical implementation barrier for KANs remains higher than for standard deep learning models, which could slow adoption in industrial settings despite the promising results.</p>
                </div>
                <div class="paper-entry" id="paper-2">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.21917v1" target="_blank">Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>Authors:</strong> Chen Wu, Ling Wang, Zhuoran Zheng et al.<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.21917v1" target="_blank">2602.21917v1</a>
                    </div>
                    <div class="paper-topics">
                        <span class="topic-tag">mamba</span>
                    </div>

                    <h4>Summary</h4>
                    <p>### 1. Research Question. The paper addresses the scalability crisis in Ultra-High-Definition (UHD) image restoration, where existing models require unsustainable computational resources to process millions of pixels. It investigates whether it is truly necessary to process every single pixel to understand and restore an image.</p>

<p>### 2. Positioning. Current state-of-the-art models rely on pixel-wise operations that become prohibitively expensive at UHD resolutions. While State Space Models (SSMs) like Mamba offer linear complexity, they still face bottlenecks due to their pixel-serial scanning nature. This work positions itself as a solution to these limitations by proposing a shift from pixel-centric to cluster-centric processing.</p>

<p>### 3. Key Contribution. The main contribution is the introduction of \(C^2\)SSM, a visual state space model that shifts the paradigm from pixel-serial to cluster-serial scanning. This method achieves state-of-the-art results across five UHD restoration tasks while significantly reducing computational costs. It challenges the standard approach to large-scale vision tasks by proving that processing sparse semantic clusters is more efficient than processing individual pixels.</p>

<p>### 4. Methodology. The authors propose a method that distills rich image features into a sparse set of semantic centroids using a neural-parameterized mixture model. The model utilizes a dual-path process that scans these cluster centers to reason over global context and then diffuses this information back to all pixels through a similarity distribution. A lightweight modulator is incorporated to ensure fine details are not lost during the reconstruction process.</p>

<p>### 5. Limitations. The abstract does not explicitly list limitations, but the reliance on semantic centroids implies a potential risk of losing subtle high-frequency details during the clustering process. The effectiveness of the diffusion step relies heavily on the accuracy of the similarity distribution, which could be a bottleneck if the initial feature distillation is imperfect. Additionally, the introduction of a neural-parameterized mixture model may add complexity to the training stability compared to standard convolutional approaches.</p>

<p>### 6. Critical Evaluation. This work offers a compelling theoretical shift by questioning the necessity of pixel-level processing in an era of massive image resolutions. The strength of the paper lies in its ability to decouple model performance from the rigid constraints of pixel-count complexity. However, the practical adoption of this method will depend on how robust the clustering mechanism is when applied to diverse visual scenes with varying levels of texture and noise.</p>
                </div>
                <div class="paper-entry" id="paper-3">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.21773v1" target="_blank">Easy to Learn, Yet Hard to Forget: Towards Robust Unlearning Under Bias</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>Authors:</strong> JuneHyoung Kwon, MiHyeon Kim, Eunju Lee et al.<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.21773v1" target="_blank">2602.21773v1</a>
                    </div>
                    <div class="paper-topics">
                        <span class="topic-tag">unlearning</span>
                    </div>

                    <h4>Summary</h4>
                    <p>### 1. Research Question. The paper aims to solve the problem of ineffective machine unlearning when models have learned spurious correlations or biases from training data. It specifically investigates why models struggle to forget specific data points that are "easy to learn" due to bias attributes, asking how to ensure true unlearning in these biased scenarios.</p>

<p>### 2. Positioning. This research positions itself at the intersection of machine unlearning and robust learning, addressing a critical gap where standard unlearning techniques fail on biased models. It challenges the assumption that unlearning methods work uniformly regardless of how the model originally learned the data. The work highlights that current methods fail to account for "shortcut unlearning," where models drop bias features instead of the target class features.</p>

<p>### 3. Key Contribution. The primary contribution is the identification of "shortcut unlearning," a phenomenon where models inadvertently unlearn bias attributes rather than the intended class attributes, paradoxically improving accuracy on the class meant to be forgotten. The paper also introduces CUPID, a novel framework that disentangles causal and bias learning pathways to achieve robust unlearning. This framework provides a mechanism to handle the "easy to learn, yet hard to forget" tendency observed in biased models.</p>

<p>### 4. Methodology. The CUPID framework operates by first partitioning the forget set into causal and bias-approximated subsets using loss landscape sharpness. It then disentangles model parameters into distinct causal and bias pathways. Finally, the method performs a targeted update by routing refined gradients to their respective pathways, ensuring the model forgets the correct attributes.</p>

<p>### 5. Limitations. A potential limitation is the reliance on loss landscape sharpness as a proxy to distinguish between causal and bias-aligned samples, which may be sensitive to hyperparameter choices or noisy data distributions. Additionally, the process of disentangling model parameters into separate pathways adds architectural complexity and computational overhead compared to standard unlearning techniques.</p>

<p>### 6. Critical Evaluation. This paper provides a valuable diagnosis of why unlearning fails in realistic, biased settings, moving beyond idealized benchmark assumptions. The proposed solution is innovative and demonstrates state-of-the-art performance on standard datasets like Waterbirds and BAR. However, the practical applicability of the method depends heavily on the stability of the sharpness metric used for data partitioning.</p>
                </div>
                <div class="paper-entry" id="paper-4">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.21798v1" target="_blank">Excitation: Momentum For Experts</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>Authors:</strong> Sagi Shaier<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.21798v1" target="_blank">2602.21798v1</a>
                    </div>
                    <div class="paper-topics">
                        <span class="topic-tag">mixture_of_experts</span>
                    </div>

                    <h4>Summary</h4>
                    <p>### 1. Research Question. The paper investigates how to improve the training efficiency and stability of sparse Mixture-of-Experts (MoE) models. It specifically asks whether dynamically modulating parameter updates based on expert utilization can overcome convergence failures often seen in deep sparse architectures.</p>

<p>### 2. Positioning. Standard optimization methods treat all parameters uniformly, failing to account for the dynamic and conditional nature of computation in sparse architectures. This work positions itself as a specialized enhancement for MoE training, filling a critical gap where traditional optimizers struggle to establish functional signal paths in deep models.</p>

<p>### 3. Key Contribution. The primary contribution is the Excitation framework, a plug-and-play optimization wrapper that accelerates learning by dynamically scaling updates according to batch-level expert usage. It introduces a competitive dynamic that sharpens routing specialization and resolves "structural confusion" without adding extra memory overhead or learnable parameters.</p>

<p>### 4. Methodology. Excitation modulates the learning process by amplifying updates for highly utilized experts while selectively suppressing updates for those with low utilization. This creates a competition among experts that encourages sharper specialization and allows the framework to act as a catalyst for establishing stable signal paths in deep networks.</p>

<p>### 5. Limitations. While the abstract claims broad success, the aggressive amplification of updates for popular experts could theoretically exacerbate training instability if not carefully managed. Additionally, the reliance on batch-level utilization statistics suggests the method's effectiveness might depend on sufficiently large batch sizes to ensure reliable routing signals.</p>

<p>### 6. Critical Evaluation. This work offers a compelling and memory-efficient solution to a specific failure mode in deep MoEs, making it highly practical for real-world applications. Its optimizer-agnostic design and lack of additional memory footprint are significant strengths, though the long-term effects of such competitive update dynamics on extreme model scaling warrant further investigation.</p>
                </div>

                <hr>

                <h3 id="references">References</h3>
                <ul>
                    <li><a href="https://arxiv.org/abs/2602.22055v1" target="_blank">Physics-Informed Machine Learning for Vessel Shaft Power and Fuel Consumption Prediction: Interpretable KAN-based Approach</a></li>
                    <li><a href="https://arxiv.org/abs/2602.21917v1" target="_blank">Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration</a></li>
                    <li><a href="https://arxiv.org/abs/2602.21773v1" target="_blank">Easy to Learn, Yet Hard to Forget: Towards Robust Unlearning Under Bias</a></li>
                    <li><a href="https://arxiv.org/abs/2602.21798v1" target="_blank">Excitation: Momentum For Experts</a></li>
                </ul>

                <p><em>Feel free to reach out for discussion and feedback. Thanks for reading!</em></p>
            </div>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2026 Beren Meng. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>