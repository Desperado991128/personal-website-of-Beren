<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SY眼动LLM研究日报 - 2026-02-28</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['\\(','\\)']], displayMath: [['\\[','\\]']]}
        });
    </script>
    <style>
        body {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            font-size: 18px;
        }
        header {
            margin-bottom: 2rem;
            border-bottom: 1px solid #eaecef;
        }
        .site-title {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 2em;
            margin-bottom: 0.5em;
        }
        nav ul {
            display: flex;
            list-style: none;
            padding: 0;
            margin: 1rem 0;
        }
        nav ul li {
            margin-right: 1.5rem;
        }
        nav ul li a {
            text-decoration: none;
            color: #0366d6;
            font-weight: 600;
        }
        nav ul li a:hover {
            text-decoration: underline;
        }
        .container {
            width: 100%;
            max-width: 800px;
        }
        h1 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 2.4em;
            margin-bottom: 0.5em;
            line-height: 1.2;
        }
        h2 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 1.8em;
            margin-top: 1.5em;
            margin-bottom: 0.75em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        h3 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 1.5em;
            margin-top: 1.2em;
            margin-bottom: 0.6em;
        }
        h4 {
            font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, serif;
            font-size: 1.2em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }
        p {
            margin: 1em 0;
        }
        code {
            font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
            background: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-size: 0.9em;
        }
        pre {
            background: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow: auto;
            font-size: 0.9em;
        }
        blockquote {
            margin: 1em 0;
            padding: 0 1em;
            color: #6a737d;
            border-left: 0.25em solid #dfe2e5;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1.5em auto;
        }
        .meta {
            color: #6a737d;
            font-size: 0.9em;
            margin-bottom: 2em;
        }
        .post-meta {
            color: #6a737d;
            font-size: 0.9em;
            margin-bottom: 2em;
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
        }
        /* SY Profile specific styling - green tint */
        .label {
            background-color: #e6f4ea;
            color: #137333;
            padding: 0.2em 0.6em;
            border-radius: 3px;
            font-size: 0.85em;
            font-weight: 600;
        }
        .figure-caption {
            text-align: center;
            color: #666;
            font-size: 0.9em;
            margin-top: -1em;
            margin-bottom: 2em;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 1.5em 0;
        }
        th, td {
            border: 1px solid #dfe2e5;
            padding: 8px 12px;
            text-align: left;
        }
        th {
            background-color: #f6f8fa;
        }
        tr:nth-child(even) {
            background-color: #f6f8fa;
        }
        #table-of-contents {
            background-color: #f0f7f0;
            padding: 1.5rem;
            border-radius: 5px;
            margin: 2rem 0;
            border-left: 4px solid #137333;
        }
        #table-of-contents h3 {
            margin-top: 0;
            margin-bottom: 1rem;
            color: #137333;
        }
        #table-of-contents ol, #table-of-contents ul {
            margin-bottom: 0;
        }
        #table-of-contents a {
            text-decoration: none;
            color: #0366d6;
        }
        #table-of-contents a:hover {
            text-decoration: underline;
        }
        .post-content {
            margin-top: 2rem;
        }
        .paper-entry {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid #eaecef;
        }
        .paper-entry:last-child {
            border-bottom: none;
        }
        .paper-title {
            font-size: 1.3em;
            margin-bottom: 0.5em;
        }
        .paper-title a {
            color: #0366d6;
            text-decoration: none;
        }
        .paper-title a:hover {
            text-decoration: underline;
        }
        .paper-meta {
            color: #6a737d;
            font-size: 0.9em;
            margin-bottom: 1em;
        }
        .paper-topics {
            display: inline-flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 0.5rem;
        }
        /* SY Profile topic tags - green tint */
        .topic-tag {
            background-color: #e6f4ea;
            color: #137333;
            padding: 0.2em 0.6em;
            border-radius: 3px;
            font-size: 0.85em;
        }
        footer {
            margin-top: 3rem;
            padding-top: 1rem;
            border-top: 1px solid #eaecef;
            font-size: 0.9em;
            color: #6a737d;
        }
        @media (max-width: 768px) {
            body {
                padding: 15px;
            }
            h1 {
                font-size: 2em;
            }
            h2 {
                font-size: 1.6em;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1 class="site-title">Beren's Blog</h1>
            <nav>
                <ul>
                  <li><a href="../index.html">Home</a></li>
                  <li><a href="../blog.html">Blog</a></li>
                  <li><a href="../gallery.html">Gallery</a></li>
                  <li><a href="../about.html">About</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="container">
        <article class="blog-post">
            <h2 class="post-title">SY眼动LLM研究日报</h2>
            <div class="post-meta">
                <span class="date">February 28, 2026</span>
                <span class="author">SY</span>
                <span class="label">眼动LLM研究</span>
            </div>

            <div id="table-of-contents">
              <h3>目录</h3>
              <ol>
                <li><a href="#daily-concept">每日概念</a></li>
                <li><a href="#papers">论文摘要</a></li>
                <li><a href="#references">参考链接</a></li>
              </ol>
            </div>

            <div class="post-content">
                <p>以下是 2026年02月28日 精选的眼动追踪与LLM交叉研究论文摘要。</p>

                <h2 id="daily-concept">每日概念: Eye tracking in multimodal AI</h2>
                <p><strong>1. 概念定义</strong><br>
这指的是将眼动追踪数据作为一种显式的模态信号整合到多模态大语言模型中。通过捕捉用户的注视点、注视时长和眼动轨迹，模型能够获得人类注意力分布的真实标签，从而增强对视觉场景或文本信息的理解与推理能力。</p>

<p><strong>2. 核心原理</strong><br>
核心机制在于利用眼动数据引导模型的注意力机制或特征选择过程。在Transformer架构中，标准的自注意力权重是隐式学习得到的，而眼动数据提供了人类认知注意力的显式先验。这通常通过将注视坐标和时间特征编码为向量，并与文本或图像特征进行融合或交叉注意力计算来实现。数学上，可以通过最小化模型注意力图与人类注视分布之间的差异来优化模型，例如使用KL散度损失函数 \(\mathcal{L}_{gaze} = D_{KL}(P_{human} \| P_{model})\)。</p>

<p><strong>3. 研究意义</strong><br>
这一交叉领域的研究对于提升多模态大模型的可解释性和效率至关重要。它能够解决模型注意力与人类注意力不对齐的问题，从而减少模型在视觉问答或文档理解任务中的幻觉现象。此外，它为构建更符合人类认知习惯的AI系统提供了生理学依据，推动了认知科学与深度学习的深度融合。</p>

<p><strong>4. 关键洞见</strong><br>
眼动数据本质上是人类认知过程的“地面真值”标签，它将生物学的注意力机制映射到了Transformer的计算注意力机制中。</p>

                <h2 id="papers">论文摘要</h2>

                <div class="paper-entry" id="paper-1">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.20408v1" target="_blank">Examining and Addressing Barriers to Diversity in LLM-Generated Ideas</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>作者:</strong> Yuting Deng, Melanie Brucks, Olivier Toubia<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.20408v1" target="_blank">2602.20408v1</a>
                    </div>
                    <div class="paper-topics">
                    </div>

                    <h4>摘要</h4>
                    <p>以下是针对技术博客读者的结构化中文总结：</p>

<p>1. <strong>研究问题</strong><br>
这篇论文旨在解决大语言模型(LLM)生成的想法多样性低于人类样本，可能导致社会创新同质化的问题。核心研究问题在于识别导致LLM想法多样性缺失的认知机制，并验证相应的干预手段。</p>

<p>2. <strong>研究定位</strong><br>
该研究将认知心理学理论引入LLM生成领域，填补了理解AI创意生成局限性的理论空白。它不仅量化了LLM在多样性上的劣势，还从个体和群体两个维度解释了其背后的认知机制，为优化人机协作提供了理论依据。</p>

<p>3. <strong>核心贡献</strong><br>
论文的主要贡献在于从理论和实证角度识别了阻碍多样性的两大机制，即个体层面的“固着效应”和集体层面的“知识聚合”。创新之处在于发现思维链提示能缓解固着，而普通角色设定能模拟人类的知识分区，两者结合后的多样性表现甚至超越了人类。</p>

<p>4. <strong>方法概述</strong><br>
论文通过四个研究提出了针对性的提示工程方法。一是利用思维链提示鼓励结构化推理以打破固着，二是使用普通人物设定替代名人设定，作为多样化的采样线索引导模型探索不同的语义空间。</p>

<p>5. <strong>局限与不足</strong><br>
尽管摘要未详述局限，但潜在不足可能包括这些提示策略在不同任务领域或模型规模上的泛化性有待验证。此外，思维链提示仅在LLM上有效而在人类上无效，这提示我们在设计人机协作流程时需要区分对待AI与人类的认知差异。</p>

<p>6. <strong>评价与思考</strong><br>
这项工作极具启发性，它巧妙地利用心理学原理解决了AI生成中的关键痛点。优点在于提供了低成本且有效的解决方案，缺点可能在于对“普通角色”的定义和选择可能仍存在主观性，未来研究可进一步探索如何自动生成最优的角色分布。</p>
                </div>
                <div class="paper-entry" id="paper-2">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.23335v1" target="_blank">Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>作者:</strong> Dany Haddad, Dan Bareket, Joseph Chee Chang et al.<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.23335v1" target="_blank">2602.23335v1</a>
                    </div>
                    <div class="paper-topics">
                    </div>

                    <h4>摘要</h4>
                    <p><strong>1. 研究问题</strong><br>
这篇论文旨在解决AI科研工具在真实研究场景中缺乏使用行为数据的问题。核心研究问题是如何理解研究人员与LLM驱动的科研助手交互的模式、参与度以及随经验积累的使用演变。</p>

<p><strong>2. 研究定位</strong><br>
这项工作填补了AI辅助科研领域在真实世界大规模交互数据方面的空白。它超越了传统的搜索日志分析，专注于LLM时代的检索增强生成(RAG)平台，为理解人机协作研究提供了实证基础。</p>

<p><strong>3. 核心贡献</strong><br>
论文的主要贡献是发布了Asta交互数据集，包含超过20万条用户查询和交互日志。研究构建了一个新的查询意图分类体系，揭示了用户将AI视为协作伙伴而非单纯搜索引擎的行为模式。</p>

<p><strong>4. 方法概述</strong><br>
研究者收集并分析了来自两个已部署工具(文献发现和科学问答界面)的大规模交互日志。通过定量分析和定性编码，研究刻画了查询复杂度、用户参与度以及引用交互的非线性特征。</p>

<p><strong>5. 局限与不足</strong><br>
数据集仅限于特定的RAG平台，可能无法完全推广到所有AI科研工具。缺乏眼动追踪等生理数据，限制了对用户注意力分配和认知负荷的深层洞察，仅能通过点击和查询行为进行间接推断。</p>

<p><strong>6. 评价与思考</strong><br>
这项工作为设计下一代AI科研助手提供了宝贵的数据支持，特别是在理解用户如何处理生成内容和引用证据方面。从眼动追踪研究的角度看，该数据集中的非线性导航模式为未来结合眼动追踪技术深入探究用户在LLM生成内容上的视觉注意力分配提供了重要的假设基础。</p>
                </div>
                <div class="paper-entry" id="paper-3">
                    <h3 class="paper-title">
                        <a href="https://arxiv.org/pdf/2602.23193v1" target="_blank">ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering</a>
                    </h3>
                    <div class="paper-meta">
                        <strong>作者:</strong> Elzo Brito dos Santos Filho<br>
                        <strong>arXiv:</strong> <a href="https://arxiv.org/abs/2602.23193v1" target="_blank">2602.23193v1</a>
                    </div>
                    <div class="paper-topics">
                    </div>

                    <h4>摘要</h4>
                    <p>以下是针对论文《ESAA. Event Sourcing for Autonomous Agents in LLM-Based Software Engineering》的结构化中文总结。</p>

<p>1. <strong>研究问题</strong><br>
这篇论文旨在解决基于LLM的自主智能体面临的结构性限制，即缺乏原生状态管理，长上下文导致的信息衰减，以及概率性生成与确定性执行需求之间的鸿沟。</p>

<p>2. <strong>研究定位</strong><br>
该工作位于软件工程架构与LLM智能体研究的交叉点。它填补了现有智能体系统在状态管理和执行可靠性方面的空白，将智能体从单纯的反应式助手转变为具有可审计性和可追溯性的工程化系统。</p>

<p>3. <strong>核心贡献</strong><br>
论文提出了ESAA架构，创新性地将事件溯源模式引入LLM智能体，将认知意图与项目状态变更解耦。其核心贡献还包括引入边界契约和哈希重放验证机制，确保了任务执行的不可变性和取证可追溯性。</p>

<p>4. <strong>方法概述</strong><br>
ESAA架构要求智能体仅输出结构化的意图JSON文件，由确定性编排器进行验证并持久化到仅追加日志中。系统随后应用文件写入效应并生成可验证的物化视图，同时利用元提示和哈希验证来保障流程的严谨性。</p>

<p>5. <strong>局限与不足</strong><br>
尽管论文通过案例研究验证了架构，但样本量相对较小，可能不足以完全证明其在更广泛复杂场景下的通用性。引入事件溯源和确定性编排增加了系统的复杂度和开销，可能对轻量级任务的执行效率产生影响。</p>

<p>6. <strong>评价与思考</strong><br>
该工作为解决LLM生成的不确定性问题提供了优雅的工程化方案，通过借鉴成熟的软件架构模式提升了智能体的可靠性。这种将认知与执行分离的思路对于构建大规模、多智能体协作系统具有重要的参考价值，尽管其实际部署的复杂性仍需进一步评估。</p>
                </div>

                <hr>

                <h3 id="references">参考链接</h3>
                <ul>
                    <li><a href="https://arxiv.org/abs/2602.20408v1" target="_blank">Examining and Addressing Barriers to Diversity in LLM-Generated Ideas</a></li>
                    <li><a href="https://arxiv.org/abs/2602.23335v1" target="_blank">Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset</a></li>
                    <li><a href="https://arxiv.org/abs/2602.23193v1" target="_blank">ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering</a></li>
                </ul>

                <p><em>欢迎讨论和反馈。感谢阅读!</em></p>
            </div>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2026 SY. All rights reserved. | Gaze/LLM Research Daily Review</p>
        </div>
    </footer>
</body>
</html>